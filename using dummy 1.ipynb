{"cells":[{"attachments":{},"cell_type":"markdown","metadata":{},"source":["# A real-world example"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["Now you will apply these concepts to a real-world dataset: "]},{"cell_type":"code","execution_count":9,"metadata":{},"outputs":[],"source":["import pandas as pd\n","import statsmodels as sm\n","import sklearn.preprocessing as preprocessing\n","from sklearn.linear_model import LogisticRegression\n","from sklearn.model_selection import train_test_split\n","from scipy import stats\n","import warnings"]},{"cell_type":"code","execution_count":10,"metadata":{},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>Age</th>\n","      <th>Education</th>\n","      <th>Occupation</th>\n","      <th>Relationship</th>\n","      <th>Race</th>\n","      <th>Sex</th>\n","      <th>Target</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>39</td>\n","      <td>Bachelors</td>\n","      <td>Adm-clerical</td>\n","      <td>Not-in-family</td>\n","      <td>White</td>\n","      <td>Male</td>\n","      <td>&lt;=50K</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>50</td>\n","      <td>Bachelors</td>\n","      <td>Exec-managerial</td>\n","      <td>Husband</td>\n","      <td>White</td>\n","      <td>Male</td>\n","      <td>&lt;=50K</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>38</td>\n","      <td>HS-grad</td>\n","      <td>Handlers-cleaners</td>\n","      <td>Not-in-family</td>\n","      <td>White</td>\n","      <td>Male</td>\n","      <td>&lt;=50K</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>53</td>\n","      <td>11th</td>\n","      <td>Handlers-cleaners</td>\n","      <td>Husband</td>\n","      <td>Black</td>\n","      <td>Male</td>\n","      <td>&lt;=50K</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>28</td>\n","      <td>Bachelors</td>\n","      <td>Prof-specialty</td>\n","      <td>Wife</td>\n","      <td>Black</td>\n","      <td>Female</td>\n","      <td>&lt;=50K</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["   Age  Education         Occupation   Relationship   Race     Sex Target\n","0   39  Bachelors       Adm-clerical  Not-in-family  White    Male  <=50K\n","1   50  Bachelors    Exec-managerial        Husband  White    Male  <=50K\n","2   38    HS-grad  Handlers-cleaners  Not-in-family  White    Male  <=50K\n","3   53       11th  Handlers-cleaners        Husband  Black    Male  <=50K\n","4   28  Bachelors     Prof-specialty           Wife  Black  Female  <=50K"]},"execution_count":10,"metadata":{},"output_type":"execute_result"}],"source":["salaries = pd.read_csv('salaries_final.csv', index_col=0)\n","salaries.head()"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["For this example, you will fit a logistic regression model to `Target` using `Age`, `Race`, and `Sex`. Since `Target`, `Race`, and `Sex` are categorical, they need to be be converted to a numeric datatype first. \n","\n","The `get_dummies()` function will only convert `object` and `category` datatypes to dummy variables so it is safe to pass `Age` to `get_dummies()`. Note that we also pass two additional arguments, `drop_first=True` and `dtype=float`. The `drop_first=True` argument removes the first level for each categorical variable and the `dtype=float` argument converts the datatype of all the dummy variables to float. The data must be float in order to obtain accurate statistical results from `statsmodels`. "]},{"cell_type":"code","execution_count":11,"metadata":{},"outputs":[],"source":["# Convert race and sex using get_dummies() \n","x_feats = ['Race', 'Sex', 'Age']\n","X = pd.get_dummies(salaries[x_feats], drop_first=True, dtype=float)\n","\n","# Convert target using get_dummies\n","y = pd.get_dummies(salaries['Target'], drop_first=True, dtype=float)\n","y = y['>50K']"]},{"cell_type":"code","execution_count":12,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Optimization terminated successfully.\n","         Current function value: 0.498651\n","         Iterations 6\n"]}],"source":["import statsmodels.api as sm\n","\n","# Create intercept term required for sm.Logit, see documentation for more information\n","X = sm.add_constant(X)\n","\n","# Fit model\n","logit_model = sm.Logit(y, X)\n","\n","# Get results of the fit\n","result = logit_model.fit()"]},{"cell_type":"code","execution_count":5,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["                           Logit Regression Results                           \n","==============================================================================\n","Dep. Variable:                   >50K   No. Observations:                32561\n","Model:                          Logit   Df Residuals:                    32554\n","Method:                           MLE   Df Model:                            6\n","Date:                Mon, 03 Jul 2023   Pseudo R-squ.:                 0.09666\n","Time:                        10:49:54   Log-Likelihood:                -16237.\n","converged:                       True   LL-Null:                       -17974.\n","Covariance Type:            nonrobust   LLR p-value:                     0.000\n","===========================================================================================\n","                              coef    std err          z      P>|z|      [0.025      0.975]\n","-------------------------------------------------------------------------------------------\n","const                      -4.4248      0.189    -23.380      0.000      -4.796      -4.054\n","Age                         0.0387      0.001     38.530      0.000       0.037       0.041\n","Race_Asian-Pac-Islander     0.9991      0.197      5.079      0.000       0.614       1.385\n","Race_Black                  0.1812      0.191      0.950      0.342      -0.193       0.555\n","Race_Other                 -0.1143      0.282     -0.406      0.685      -0.667       0.438\n","Race_White                  0.8742      0.183      4.782      0.000       0.516       1.232\n","Sex_Male                    1.2069      0.035     34.380      0.000       1.138       1.276\n","===========================================================================================\n"]}],"source":["print(result.summary())"]},{"cell_type":"code","execution_count":6,"metadata":{},"outputs":[{"data":{"application/javascript":"\n        if (window._pyforest_update_imports_cell) { window._pyforest_update_imports_cell('import numpy as np\\nimport pandas as pd'); }\n    ","text/plain":["<IPython.core.display.Javascript object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/plain":["const                      0.011977\n","Age                        1.039480\n","Race_Asian-Pac-Islander    2.715861\n","Race_Black                 1.198638\n","Race_Other                 0.891987\n","Race_White                 2.396965\n","Sex_Male                   3.343142\n","dtype: float64"]},"execution_count":6,"metadata":{},"output_type":"execute_result"}],"source":["np.exp(result.params)"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["You can also use scikit-learn to retrieve the parameter estimates. The disadvantage here though is that there are no p-values for your parameter estimates!"]},{"cell_type":"code","execution_count":7,"metadata":{},"outputs":[{"data":{"text/html":["<style>#sk-container-id-1 {color: black;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LogisticRegression(C=1000000000000000.0, fit_intercept=False,\n","                   solver=&#x27;liblinear&#x27;)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LogisticRegression</label><div class=\"sk-toggleable__content\"><pre>LogisticRegression(C=1000000000000000.0, fit_intercept=False,\n","                   solver=&#x27;liblinear&#x27;)</pre></div></div></div></div></div>"],"text/plain":["LogisticRegression(C=1000000000000000.0, fit_intercept=False,\n","                   solver='liblinear')"]},"execution_count":7,"metadata":{},"output_type":"execute_result"}],"source":["logreg = LogisticRegression(fit_intercept = False, C = 1e15, solver='liblinear')\n","model_log = logreg.fit(X, y)\n","model_log"]},{"cell_type":"code","execution_count":8,"metadata":{},"outputs":[{"data":{"text/plain":["array([[-4.38706344,  0.03871011,  0.96178903,  0.14397984, -0.14384057,\n","         0.83689458,  1.2067121 ]])"]},"execution_count":8,"metadata":{},"output_type":"execute_result"}],"source":["model_log.coef_"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["## Summary \n","\n","In this lab you built upon your previous knowledge of linear regression and built an intuitive understanding of how this could be adapted for classification. We then demonstrated tools for performing logistic regression. In the upcoming lessons you will continue to investigate logistic regression from other viewpoints."]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.9"}},"nbformat":4,"nbformat_minor":2}
